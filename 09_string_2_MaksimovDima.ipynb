{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\alisa\\anaconda\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\alisa\\anaconda\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\alisa\\anaconda\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\alisa\\anaconda\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import random\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial import distance\n",
    "import pymorphy2\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['высокопревосходительства',\n",
       " 'попреблагорассмотрительст',\n",
       " 'попреблагорассмотрительствующемуся',\n",
       " 'убегающих',\n",
       " 'уменьшившейся']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'\n",
    "with open (\"litw-win.txt\", \"r\", encoding='windows-1251') as f:\n",
    "    words = [line.strip().split()[1] for line in f]\n",
    "words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lst = []\n",
    "for i in text.split():\n",
    "    f_lst.append(min(words, key=lambda w: edit_distance(w, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(f_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3= ( 'Считайте слова из файла litw-win.txt и запишите их в список words.\\\n",
    "В заданном предложении исправьте все опечатки, заменив слова с опечатками на\\\n",
    "ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка,\\\n",
    "если данное слово не содержится в списке words')\n",
    "stemmer = nltk.SnowballStemmer('russian')\n",
    "lemmer = pymorphy2.MorphAnalyzer()\n",
    "word2  = [[word, stemmer.stem(word), lemmer.parse(word)[0].normal_form] for word in nltk.word_tokenize(text3) if word not in string.punctuation]\n",
    "df2 = pd.DataFrame(word2, columns=['word', 'stemma', 'lemma'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 3, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3= ( 'Считайте слова из файла litw-win.txt и запишите их в список words.\\\n",
    "В заданном предложении исправьте все опечатки, заменив слова с опечатками на\\\n",
    "ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка,\\\n",
    "если данное слово не содержится в списке words')\n",
    "CountVectorizer().fit_transform(nltk.sent_tokenize(text3)).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32868\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('preprocessed_descriptions.csv')\n",
    "data['preprocessed_descriptions'] = data['preprocessed_descriptions'].astype(str)\n",
    "descriptions = ' '.join(list(data['preprocessed_descriptions']))\n",
    "total_words = list(nltk.word_tokenize(descriptions.lower()))\n",
    "words = set(nltk.word_tokenize(descriptions.lower()))\n",
    "print(len(words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differencere - aiken. Расстояние редактирования: 9\n",
      "kathy - proceeding. Расстояние редактирования: 10\n",
      "810 - syruptime. Расстояние редактирования: 9\n",
      "makeno - deficient. Расстояние редактирования: 7\n",
      "lumpia - plethora. Расстояние редактирования: 6\n"
     ]
    }
   ],
   "source": [
    "words2 = list(words)\n",
    "lst = []\n",
    "for i in range(5):\n",
    "    w1, w2 = random.sample(words2, 2)\n",
    "    lst.append(f'{w1} - {w2}. Расстояние редактирования: {nltk.edit_distance(w1, w2)}')\n",
    "print(*lst, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'яблоко': 7, 'банан': 7, 'apple': 8, 'груша': 8, 'киви': 7, 'ананас': 6, 'манго': 8, 'арбуз': 7, 'слива': 7, 'виноград': 8, 'гранат': 8, 'лимонад': 8, 'персиммон': 6, 'крыжовник': 8, 'голубика': 7, 'бананчик': 7, 'апельсинчик': 3, 'аппак': 6, 'ааппельсин': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['апельсин - ааппельсин. Близость слов: 2',\n",
       " 'апельсин - апельсинчик. Близость слов: 3',\n",
       " 'апельсин - ананас. Близость слов: 6']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance(word, k):\n",
    "    words = ['яблоко', 'банан', 'апельсин','apple', 'груша', 'киви', 'ананас', 'манго', 'арбуз', 'слива',\\\n",
    "         'виноград', 'гранат', 'лимонад', 'персиммон', 'крыжовник', 'голубика', 'бананчик', 'апельсинчик', 'аппак','ааппельсин']\n",
    "    d = {i:edit_distance(word, i) for i in words if i != word}\n",
    "    print(d)\n",
    "    lst = list(sorted(d.values()))[:k]\n",
    "    f_lst = []\n",
    "    for i in lst:\n",
    "        for key,v in d.items():\n",
    "            if v == i:\n",
    "                f_lst.append(f'{word} - {key}. Близость слов: {v}')\n",
    "            if len(f_lst) == k:\n",
    "                break\n",
    "    return f_lst\n",
    "distance('апельсин', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variation</th>\n",
       "      <td>variat</td>\n",
       "      <td>variation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lora</th>\n",
       "      <td>lora</td>\n",
       "      <td>lora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starter</th>\n",
       "      <td>starter</td>\n",
       "      <td>starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skimp</th>\n",
       "      <td>skimp</td>\n",
       "      <td>skimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sabra</th>\n",
       "      <td>sabra</td>\n",
       "      <td>sabra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>septoct</th>\n",
       "      <td>septoct</td>\n",
       "      <td>septoct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kibbeh</th>\n",
       "      <td>kibbeh</td>\n",
       "      <td>kibbeh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itnote</th>\n",
       "      <td>itnot</td>\n",
       "      <td>itnote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dorion</th>\n",
       "      <td>dorion</td>\n",
       "      <td>dorion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325f</th>\n",
       "      <td>325f</td>\n",
       "      <td>325f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stemmed_word normalized_word\n",
       "word                                  \n",
       "variation       variat       variation\n",
       "lora              lora            lora\n",
       "starter        starter         starter\n",
       "skimp            skimp           skimp\n",
       "sabra            sabra           sabra\n",
       "...                ...             ...\n",
       "septoct        septoct         septoct\n",
       "kibbeh          kibbeh          kibbeh\n",
       "itnote           itnot          itnote\n",
       "dorion          dorion          dorion\n",
       "325f              325f            325f\n",
       "\n",
       "[32868 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df = pd.DataFrame(words, columns = ['word'])\n",
    "df['stemmed_word'] = df.apply(lambda x: stemmer.stem(x['word']), axis = 1)\n",
    "df['normalized_word'] = df.apply(lambda x: lemmatizer.lemmatize(x['word']), axis = 1)\n",
    "df = df.set_index('word')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля от общего кол-ва, которую составляли стоп слова: 0.45646494716721886\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>original recipe created chef scott meskan geor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>children friends ask homemade popsicles mornin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>go surprised even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>sisterinlaw made us family get together delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>think fondue romantic casual dinner wonderful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29995</td>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>based french recipe changed substantially warn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29996</td>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>traditional fresh plum cake thought originated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>traditional late summer early fall snack usual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>delicious soup originally found better homes g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>ive heard cookies design company never tried c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          name  \\\n",
       "0               0         george s at the cove  black bean soup   \n",
       "1               1            healthy for them  yogurt popsicles   \n",
       "2               2                  i can t believe it s spinach   \n",
       "3               3                          italian  gut busters   \n",
       "4               4      love is in the air  beef fondue   sauces   \n",
       "...           ...                                           ...   \n",
       "29995       29995  zurie s holey rustic olive and cheddar bread   \n",
       "29996       29996          zwetschgenkuchen  bavarian plum cake   \n",
       "29997       29997   zwiebelkuchen   southwest german onion cake   \n",
       "29998       29998                                   zydeco soup   \n",
       "29999       29999        cookies by design   cookies on a stick   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "0      original recipe created chef scott meskan geor...  \n",
       "1      children friends ask homemade popsicles mornin...  \n",
       "2                                      go surprised even  \n",
       "3      sisterinlaw made us family get together delici...  \n",
       "4      think fondue romantic casual dinner wonderful ...  \n",
       "...                                                  ...  \n",
       "29995  based french recipe changed substantially warn...  \n",
       "29996  traditional fresh plum cake thought originated...  \n",
       "29997  traditional late summer early fall snack usual...  \n",
       "29998  delicious soup originally found better homes g...  \n",
       "29999  ive heard cookies design company never tried c...  \n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['preprocessed_descriptions'] = data['preprocessed_descriptions'].\\\n",
    "apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "words3 = [word for word in total_words if word not in stop_words]\n",
    "print('Доля от общего кол-ва, которую составляли стоп слова:', 1 - len(words3)/len(total_words))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "до удаления стоп-слов\n",
      "the - 40072\n",
      "a - 34951\n",
      "and - 30245\n",
      "this - 26859\n",
      "i - 24836\n",
      "to - 23471\n",
      "is - 20285\n",
      "it - 19756\n",
      "of - 18364\n",
      "for - 15939\n",
      "---------------------\n",
      "после удаления стоп-слов\n",
      "recipe - 14871\n",
      "make - 6326\n",
      "time - 5137\n",
      "use - 4620\n",
      "great - 4430\n",
      "like - 4167\n",
      "easy - 4152\n",
      "one - 3872\n",
      "made - 3810\n",
      "good - 3791\n"
     ]
    }
   ],
   "source": [
    "print('до удаления стоп-слов')\n",
    "for k, v in nltk.FreqDist(total_words).most_common(10):\n",
    "    print(f'{k} - {v}')\n",
    "print('---------------------')\n",
    "print('после удаления стоп-слов')\n",
    "for k, v in nltk.FreqDist(words3).most_common(10):\n",
    "    print(f'{k} - {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рецепт 1\n",
      "\n",
      "[[0.         0.         0.25136527 0.         0.31156077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25136527 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31156077 0.         0.31156077 0.\n",
      "  0.         0.31156077 0.         0.         0.         0.31156077\n",
      "  0.         0.31156077 0.         0.         0.31156077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31156077 0.         0.         0.\n",
      "  0.         0.31156077]] \n",
      "\n",
      "Рецепт 2\n",
      "\n",
      "[[0.         0.         0.20329067 0.         0.         0.\n",
      "  0.         0.         0.         0.25197355 0.         0.25197355\n",
      "  0.25197355 0.25197355 0.25197355 0.25197355 0.         0.\n",
      "  0.         0.         0.         0.16874962 0.         0.\n",
      "  0.         0.         0.20329067 0.         0.         0.\n",
      "  0.         0.         0.25197355 0.25197355 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25197355 0.         0.         0.\n",
      "  0.         0.         0.         0.25197355 0.         0.\n",
      "  0.25197355 0.25197355 0.         0.25197355 0.         0.25197355\n",
      "  0.         0.        ]] \n",
      "\n",
      "Рецепт 3\n",
      "\n",
      "[[0.         0.26726124 0.         0.26726124 0.         0.\n",
      "  0.26726124 0.26726124 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.26726124 0.26726124 0.         0.26726124 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26726124 0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.26726124 0.         0.26726124 0.\n",
      "  0.         0.         0.         0.         0.26726124 0.\n",
      "  0.         0.        ]] \n",
      "\n",
      "Рецепт 4\n",
      "\n",
      "[[0.18748659 0.         0.         0.         0.         0.18748659\n",
      "  0.         0.         0.18748659 0.         0.18748659 0.\n",
      "  0.         0.         0.         0.         0.18748659 0.18748659\n",
      "  0.         0.         0.         0.12556195 0.         0.18748659\n",
      "  0.18748659 0.18748659 0.         0.18748659 0.         0.18748659\n",
      "  0.18748659 0.18748659 0.         0.         0.         0.18748659\n",
      "  0.         0.18748659 0.         0.37497318 0.         0.18748659\n",
      "  0.18748659 0.         0.18748659 0.18748659 0.         0.\n",
      "  0.18748659 0.         0.         0.18748659 0.         0.18748659\n",
      "  0.         0.18748659 0.         0.         0.         0.18748659\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]] \n",
      "\n",
      "Рецепт 5\n",
      "\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.36063833 0.         0.\n",
      "  0.         0.         0.         0.         0.53849791 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.53849791 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.53849791 0.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df31 = data.sample(n=5)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df31['preprocessed_descriptions'])\n",
    "for i, vector in enumerate(vectors):\n",
    "    print(f\"Рецепт {i+1}\\n\")\n",
    "    print(vector.toarray(), '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>italian vegetable pancakes</th>\n",
       "      <th>cheezy chicken parmesan with zucchini  pasta</th>\n",
       "      <th>easy cherry pie bars</th>\n",
       "      <th>chicken sate</th>\n",
       "      <th>huckleberry rhubarb jam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>italian vegetable pancakes</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheezy chicken parmesan with zucchini  pasta</th>\n",
       "      <td>0.1022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.060858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy cherry pie bars</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken sate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huckleberry rhubarb jam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                         italian vegetable pancakes  \\\n",
       "                                                                          \n",
       "italian vegetable pancakes                                            1   \n",
       "cheezy chicken parmesan with zucchini  pasta                     0.1022   \n",
       "easy cherry pie bars                                                0.0   \n",
       "chicken sate                                                        0.0   \n",
       "huckleberry rhubarb jam                                             0.0   \n",
       "\n",
       "name                                         cheezy chicken parmesan with zucchini  pasta  \\\n",
       "                                                                                            \n",
       "italian vegetable pancakes                                                         0.1022   \n",
       "cheezy chicken parmesan with zucchini  pasta                                            1   \n",
       "easy cherry pie bars                                                                  0.0   \n",
       "chicken sate                                                                     0.021189   \n",
       "huckleberry rhubarb jam                                                          0.060858   \n",
       "\n",
       "name                                         easy cherry pie bars  \\\n",
       "                                                                    \n",
       "italian vegetable pancakes                                    0.0   \n",
       "cheezy chicken parmesan with zucchini  pasta                  0.0   \n",
       "easy cherry pie bars                                            1   \n",
       "chicken sate                                                  0.0   \n",
       "huckleberry rhubarb jam                                       0.0   \n",
       "\n",
       "name                                         chicken sate  \\\n",
       "                                                            \n",
       "italian vegetable pancakes                            0.0   \n",
       "cheezy chicken parmesan with zucchini  pasta     0.021189   \n",
       "easy cherry pie bars                                  0.0   \n",
       "chicken sate                                            1   \n",
       "huckleberry rhubarb jam                          0.045282   \n",
       "\n",
       "name                                         huckleberry rhubarb jam  \n",
       "                                                                      \n",
       "italian vegetable pancakes                                       0.0  \n",
       "cheezy chicken parmesan with zucchini  pasta                0.060858  \n",
       "easy cherry pie bars                                             0.0  \n",
       "chicken sate                                                0.045282  \n",
       "huckleberry rhubarb jam                                            1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "df31['preprocessed_descriptions'] = df31['preprocessed_descriptions'].astype(str)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df31['preprocessed_descriptions']).toarray()\n",
    "df32 = pd.DataFrame(index = df31['name'], columns = df31['name'])\n",
    "for i, r1 in enumerate(df31['name']):\n",
    "    for j, r2 in enumerate(df31['name']):\n",
    "        df32.at[r1, r2] = 1 - cosine(vectors[i], vectors[j])\n",
    "df32 = df32.reset_index().rename(columns={'name': ' '})\n",
    "df32 = df32.set_index(' ')\n",
    "df32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее похожие рецепты: italian vegetable pancakes и cheezy chicken parmesan with zucchini pasta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10220042776744487"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df33 = df32.where(df32 != 1).max().max()\n",
    "print('Наиболее похожие рецепты: italian vegetable pancakes и cheezy chicken parmesan with zucchini pasta')\n",
    "df33"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
